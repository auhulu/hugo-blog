+++
title = '20250829'
date = 2025-08-29T00:27:39+09:00
draft = false
+++
LLM自作入門を読んだので章ごとにメモ。

## 1章
知っている内容なのでさっと流した。

## 2章
そもそもエンコーダーとしての出力は次トークンのみの確率分布だと思っていたので入力と同じ長さなのは知らなかった。考えてみればそうか。  
相対位置埋め込みの方がよさそうに見えるがgpt-2の頃だとおそらくBERT的な世界観に近くてある程度以下の入力しか想定していないとしたら確かにそちらの方が安定しそうでによさそう。今のLLMは相対位置埋め込みが主流っぽい。

## 3章
Multi-head Attentionについて数式は追ったことはあったが実際に実装してみるとやっぱり実感を持って理解というか把握できるのでよいなと思った。  
Attentionの発想自体は納得感があるがQ,K,Vにわけてコンテキストベクトルを得るみたいな流れは感覚的に必然感に欠けるというか普通にもっとよいアーキテクチャが存在するのではという気持ちになる。が実際そうだとしても現状うまくいっているしあえてリスクをとって冒険するほどでもないということなのかも。

## 4章
ざっと流した。せっかくなのであとで自分で手を動かしたい。

## 5章
そういえばデコード戦略についてはtemperture, top-k, top-pなどあれど基本的には貪欲法だと認識しているがビームサーチなどの方が直感的によさそうかもとは思った。ただそのためには学習のやりも変えないといけないだろうしわざわざやるほどでもないのか。  
ちゃんと4章で作成したモデルに既存の重みを読み込めば動くというのはすごい。

## 6章
出力層を分類層に置き換えるだけで基本的な機械学習の話だったので流した。6.1の練習でこのレベルのモデルだとパディングを広げると予測性能が大分落ちるというのはへーと思った。

## 7章
システムプロンプトはチューニング時のプロンプトスタイルによるものだったのだなと納得した。ただシステムプロンプトという概念が定着した理由は気になる。  
思っていたよりもインストラクションチューニングが軽い割に効果が大きくて驚いた。もっと大規模にやる必要があるものだと思っていたので。  
読んだだけだが手を動かすという意味では7-3練習のAlpacaのファインチューニングと7-4練習のLoRAによるファインチューニングは課題としてちょうどよさそうなので手元のGPUでいつか試してみたい。